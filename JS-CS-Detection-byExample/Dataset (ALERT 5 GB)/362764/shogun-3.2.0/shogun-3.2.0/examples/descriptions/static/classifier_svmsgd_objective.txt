In this example a two-class linear support vector machine classifier is trained
on randomly generated data. As training algorithm the Stochastic Gradient
Descent (SGD) solver is used with the SVM regularization parameter C=10 and the
bias term in the classification rule switched off. The example also shows how to
compute classifier outputs on the test data and the value of the primal SVM
objective function.

For more details on the SGD solver see
 L. Bottou, O. Bousquet. The tradeoff of large scale learning. In NIPS 20. MIT
 Press. 2008.
