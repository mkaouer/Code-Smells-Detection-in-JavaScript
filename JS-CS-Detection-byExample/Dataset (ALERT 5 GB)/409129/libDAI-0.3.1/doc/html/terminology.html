<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>libDAI: Terminology and conventions</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="customdoxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">libDAI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.1.2 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Terminology and conventions </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="terminology-graphicalmodels"></a>
Graphical models</h1>
<p>Commonly used graphical models are Bayesian networks and Markov random fields. In libDAI, both types of graphical models are represented by a slightly more general type of graphical model: a factor graph [<a class="el" href="bibliography.html#KFL01">KFL01</a>].</p>
<p>An example of a Bayesian network is: </p>
<div align="center">
<img src="dot_inline_dotgraph_2.png" alt="dot_inline_dotgraph_2.png" border="0" usemap="#dot_inline_dotgraph_2.map"/>
<map name="dot_inline_dotgraph_2.map" id="dot_inline_dotgraph_2.map"></map>
</div>
<p> The probability distribution of a Bayesian network factorizes as: </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ P(\mathbf{x}) = \prod_{i\in\mathcal{V}} P(x_i \,|\, x_{\mathrm{pa}(i)}) \]" src="form_14.png"/>
</p>
<p> where <img class="formulaInl" alt="$\mathrm{pa}(i)$" src="form_15.png"/> are the parents of node <em>i</em> in a DAG.</p>
<p>The same probability distribution can be represented as a Markov random field: </p>
<div align="center">
<img src="dot_inline_dotgraph_3.png" alt="dot_inline_dotgraph_3.png" border="0" usemap="#dot_inline_dotgraph_3.map"/>
<map name="dot_inline_dotgraph_3.map" id="dot_inline_dotgraph_3.map"></map>
</div>
<p>The probability distribution of a Markov random field factorizes as: </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ P(\mathbf{x}) = \frac{1}{Z} \prod_{C\in\mathcal{C}} \psi_C(x_C) \]" src="form_16.png"/>
</p>
<p> where <img class="formulaInl" alt="$ \mathcal{C} $" src="form_17.png"/> are the cliques of an undirected graph, <img class="formulaInl" alt="$ \psi_C(x_C) $" src="form_18.png"/> are "potentials" or "compatibility functions", and <img class="formulaInl" alt="$ Z $" src="form_19.png"/> is the partition sum which properly normalizes the probability distribution.</p>
<p>Finally, the same probability distribution can be represented as a factor graph: </p>
<div align="center">
<img src="dot_inline_dotgraph_4.png" alt="dot_inline_dotgraph_4.png" border="0" usemap="#dot_inline_dotgraph_4.map"/>
<map name="dot_inline_dotgraph_4.map" id="dot_inline_dotgraph_4.map"></map>
</div>
<p>The probability distribution of a factor graph factorizes as: </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ P(\mathbf{x}) = \frac{1}{Z} \prod_{I\in \mathcal{F}} f_I(x_I) \]" src="form_20.png"/>
</p>
<p> where <img class="formulaInl" alt="$ \mathcal{F} $" src="form_21.png"/> are the factor nodes of a factor graph (a bipartite graph consisting of variable nodes and factor nodes), <img class="formulaInl" alt="$ f_I(x_I) $" src="form_22.png"/> are the factors, and <img class="formulaInl" alt="$ Z $" src="form_19.png"/> is the partition sum which properly normalizes the probability distribution.</p>
<p>Looking at the expressions for the joint probability distributions, it is obvious that Bayesian networks and Markov random fields can both be easily represented as factor graphs. Factor graphs most naturally express the factorization structure of a probability distribution, and hence are a convenient representation for approximate inference algorithms, which all try to exploit this factorization. This is why libDAI uses a factor graph as representation of a graphical model, implemented in the <a class="el" href="classdai_1_1FactorGraph.html" title="Represents a factor graph.">dai::FactorGraph</a> class.</p>
<h1><a class="anchor" id="terminology-inference"></a>
Inference tasks</h1>
<p>Given a factor graph, specified by the variable nodes <img class="formulaInl" alt="$\{x_i\}_{i\in\mathcal{V}}$" src="form_23.png"/> the factor nodes <img class="formulaInl" alt="$ \mathcal{F} $" src="form_21.png"/>, the graph structure, and the factors <img class="formulaInl" alt="$\{f_I(x_I)\}_{I\in\mathcal{F}}$" src="form_24.png"/>, the following tasks are important:</p>
<ul>
<li>Calculating the partition sum: <p class="formulaDsp">
<img class="formulaDsp" alt="\[ Z = \sum_{\mathbf{x}_{\mathcal{V}}} \prod_{I \in \mathcal{F}} f_I(x_I) \]" src="form_25.png"/>
</p>
</li>
<li>Calculating the marginal distribution of a subset of variables <img class="formulaInl" alt="$\{x_i\}_{i\in A}$" src="form_26.png"/>: <p class="formulaDsp">
<img class="formulaDsp" alt="\[ P(\mathbf{x}_{A}) = \frac{1}{Z} \sum_{\mathbf{x}_{\mathcal{V}\setminus A}} \prod_{I \in \mathcal{F}} f_I(x_I) \]" src="form_27.png"/>
</p>
</li>
<li>Calculating the MAP state which has the maximum probability mass: <p class="formulaDsp">
<img class="formulaDsp" alt="\[ \mathrm{argmax}_{\mathbf{x}}\,\prod_{I\in\mathcal{F}} f_I(x_I) \]" src="form_28.png"/>
</p>
</li>
</ul>
<p>libDAI offers several inference algorithms, which solve (a subset of) these tasks either approximately or exactly, for factor graphs with discrete variables. The following algorithms are implemented:</p>
<p>Exact inference:</p>
<ul>
<li>Brute force enumeration: <a class="el" href="classdai_1_1ExactInf.html" title="Exact inference algorithm using brute force enumeration (mainly useful for testing purposes)...">dai::ExactInf</a></li>
<li>Junction-tree method: <a class="el" href="classdai_1_1JTree.html" title="Exact inference algorithm using junction tree.">dai::JTree</a></li>
</ul>
<p>Approximate inference:</p>
<ul>
<li>Mean Field: <a class="el" href="classdai_1_1MF.html" title="Approximate inference algorithm &quot;Mean Field&quot;.">dai::MF</a></li>
<li>(Loopy) Belief Propagation: <a class="el" href="classdai_1_1BP.html" title="Approximate inference algorithm &quot;(Loopy) Belief Propagation&quot;.">dai::BP</a> [<a class="el" href="bibliography.html#KFL01">KFL01</a>]</li>
<li>Fractional Belief Propagation: <a class="el" href="classdai_1_1FBP.html" title="Approximate inference algorithm &quot;Fractional Belief Propagation&quot; [WiH03].">dai::FBP</a> [<a class="el" href="bibliography.html#WiH03">WiH03</a>]</li>
<li>Tree-Reweighted Belief Propagation: <a class="el" href="classdai_1_1TRWBP.html" title="Approximate inference algorithm &quot;Tree-Reweighted Belief Propagation&quot; [WJW03].">dai::TRWBP</a> [<a class="el" href="bibliography.html#WJW03">WJW03</a>]</li>
<li>Tree Expectation Propagation: <a class="el" href="classdai_1_1TreeEP.html" title="Approximate inference algorithm &quot;Tree Expectation Propagation&quot; [MiQ04].">dai::TreeEP</a> [<a class="el" href="bibliography.html#MiQ04">MiQ04</a>]</li>
<li>Generalized Belief Propagation: <a class="el" href="classdai_1_1HAK.html" title="Approximate inference algorithm: implementation of single-loop (&quot;Generalized Belief Propagation&quot;) and...">dai::HAK</a> [<a class="el" href="bibliography.html#YFW05">YFW05</a>]</li>
<li>Double-loop GBP: <a class="el" href="classdai_1_1HAK.html" title="Approximate inference algorithm: implementation of single-loop (&quot;Generalized Belief Propagation&quot;) and...">dai::HAK</a> [<a class="el" href="bibliography.html#HAK03">HAK03</a>]</li>
<li>Loop Corrected Belief Propagation: <a class="el" href="classdai_1_1MR.html" title="Approximate inference algorithm by Montanari and Rizzo [MoR05].">dai::MR</a> [<a class="el" href="bibliography.html#MoR05">MoR05</a>] and <a class="el" href="classdai_1_1LC.html" title="Approximate inference algorithm &quot;Loop Corrected Belief Propagation&quot; [MoK07].">dai::LC</a> [<a class="el" href="bibliography.html#MoK07">MoK07</a>]</li>
<li>Gibbs sampling: <a class="el" href="classdai_1_1Gibbs.html" title="Approximate inference algorithm &quot;Gibbs sampling&quot;.">dai::Gibbs</a></li>
<li>Conditioned Belief Propagation: <a class="el" href="classdai_1_1CBP.html" title="Class for CBP (Conditioned Belief Propagation) [EaG09].">dai::CBP</a> [<a class="el" href="bibliography.html#EaG09">EaG09</a>]</li>
<li>Decimation algorithm: <a class="el" href="classdai_1_1DecMAP.html" title="Approximate inference algorithm DecMAP, which constructs a MAP state by decimation.">dai::DecMAP</a></li>
</ul>
<p>Not all inference tasks are implemented by each method: calculating MAP states is only possible with <a class="el" href="classdai_1_1JTree.html" title="Exact inference algorithm using junction tree.">dai::JTree</a>, <a class="el" href="classdai_1_1BP.html" title="Approximate inference algorithm &quot;(Loopy) Belief Propagation&quot;.">dai::BP</a> and dai::DECMAP; calculating partition sums is not possible with <a class="el" href="classdai_1_1MR.html" title="Approximate inference algorithm by Montanari and Rizzo [MoR05].">dai::MR</a>, <a class="el" href="classdai_1_1LC.html" title="Approximate inference algorithm &quot;Loop Corrected Belief Propagation&quot; [MoK07].">dai::LC</a> and <a class="el" href="classdai_1_1Gibbs.html" title="Approximate inference algorithm &quot;Gibbs sampling&quot;.">dai::Gibbs</a>.</p>
<h1><a class="anchor" id="terminology-learning"></a>
Parameter learning</h1>
<p>In addition, libDAI supports parameter learning of conditional probability tables by Expectation Maximization (or Maximum Likelihood, if there is no missing data). This is implemented in <a class="el" href="classdai_1_1EMAlg.html" title="EMAlg performs Expectation Maximization to learn factor parameters.">dai::EMAlg</a>.</p>
<h1><a class="anchor" id="terminology-variables-states"></a>
Variables and states</h1>
<p>Linear states are a concept that is used often in libDAI, for example for storing and accessing factors, which are functions mapping from states of a set of variables to the real numbers. Internally, a factor is stored as an array, and the array index of an entry corresponds with the linear state of the set of variables. Below we will define variables, states and linear states of (sets of) variables.</p>
<h2><a class="anchor" id="terminology-variables"></a>
Variables</h2>
<p>Each (random) <em>variable</em> has a unique identifier, its <em>label</em> (which has a non-negative integer value). If two variables have the same label, they are considered as identical. A variable can take on a finite number of different values or <em>states</em>.</p>
<p>We use the following notational conventions. The discrete random variable with label <img class="formulaInl" alt="$l$" src="form_29.png"/> is denoted as <img class="formulaInl" alt="$x_l$" src="form_30.png"/>, and the number of possible values of this variable as <img class="formulaInl" alt="$S_{x_l}$" src="form_31.png"/> or simply <img class="formulaInl" alt="$S_l$" src="form_32.png"/>. The set of possible values of variable <img class="formulaInl" alt="$x_l$" src="form_30.png"/> is denoted <img class="formulaInl" alt="$X_l := \{0,1,\dots,S_l-1\}$" src="form_33.png"/> and called its <em>state</em> <em>space</em>.</p>
<h2><a class="anchor" id="terminology-variable-sets"></a>
Sets of variables and the canonical ordering</h2>
<p>Let <img class="formulaInl" alt="$A := \{x_{l_1},x_{l_2},\dots,x_{l_n}\}$" src="form_34.png"/> be a set of variables.</p>
<p>The <em>canonical</em> <em>ordering</em> of the variables in <em>A</em> is induced by their labels. That is: if <img class="formulaInl" alt="$l_1 < l_2$" src="form_35.png"/>, then <img class="formulaInl" alt="$x_{l_1}$" src="form_36.png"/> occurs before <img class="formulaInl" alt="$x_{l_2}$" src="form_37.png"/> in the canonical ordering. Below, we will assume that <img class="formulaInl" alt="$(l_i)_{i=1}^n$" src="form_38.png"/> is ordered according to the canonical ordering, i.e., <img class="formulaInl" alt="$l_1 < l_2 < \dots < l_n$" src="form_39.png"/>.</p>
<h2><a class="anchor" id="terminology-variable-states"></a>
States and linear states of sets of variables</h2>
<p>A <em>state</em> of the variables in <em>A</em> refers to a joint assignment of the variables, or in other words, to an element of the Cartesian product <img class="formulaInl" alt="$ \prod_{i=1}^n X_{l_i}$" src="form_40.png"/> of the state spaces of the variables in <em>A</em>. Note that a state can also be interpreted as a mapping from variables (or variable labels) to the natural numbers, which assigns to a variable (or its label) the corresponding state of the variable.</p>
<p>A state of <em>n</em> variables can be represented as an n-tuple of non-negative integers: <img class="formulaInl" alt="$(s_1,s_2,\dots,s_n)$" src="form_41.png"/> corresponds to the joint assignment <img class="formulaInl" alt="$x_{l_1} = s_1, \dots, x_{l_n} = s_n$" src="form_42.png"/>. Alternatively, a state can be represented compactly as one non-negative integer; this representation is called a <em>linear</em> <em>state</em>. The linear state <em>s</em> corresponding to the state <img class="formulaInl" alt="$(s_1,s_2,\dots,s_n)$" src="form_41.png"/> would be: </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ s := \sum_{i=1}^n s_i \prod_{j=1}^{i-1} S_{l_j} = s_1 + s_2 S_{l_1} + s_3 S_{l_1} S_{l_2} + \dots + s_n S_{l_1} \cdots S_{l_{n-1}}. \]" src="form_43.png"/>
</p>
<p>Vice versa, given a linear state <em>s</em> for the variables <em>A</em>, the corresponding state <img class="formulaInl" alt="$s_i$" src="form_44.png"/> of the <em>i</em> 'th variable <img class="formulaInl" alt="$x_{l_i}$" src="form_45.png"/> (according to the canonical ordering of the variables in <em>A</em>) is given by </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ s_i = \left\lfloor\frac{s \mbox { mod } \prod_{j=1}^i S_{l_j}}{\prod_{j=1}^{i-1} S_{l_j}}\right\rfloor. \]" src="form_46.png"/>
</p>
<p>Finally, the <em>number</em> <em>of</em> <em>states</em> of the set of variables <em>A</em> is simply the number of different joint assignments of the variables, that is, <img class="formulaInl" alt="$\prod_{i=1}^n S_{l_i}$" src="form_47.png"/>. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Mon Sep 17 2012 12:30:35 for libDAI by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.1.2
</small></address>
</body>
</html>
